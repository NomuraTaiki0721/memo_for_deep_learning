#深層学習まとめ
深層学習で調べたことをまとめる
##基本
Hintonが2006年に発表したボルツマンマシンがベース。
誤差逆伝播やlong short term memory法により学習。
###内部表現
*特徴*や*潜在表現*とも呼ばれる。層が多いNNによって観測データから本質的な情報を抽出したもの。
次元削減ともいい、入力情報から認識に必要な低次元の情報を取り出し、その情報を用いて認識を行うことは有効である場合が多い。
*ノーフリーランチ定理no free lunch thorem*ではすべてのタスクに対して他より優れた性能を示す万能アルゴリズムが存在しないことを証明している。

##深層ニューラルネット
狭義の意味では4層以上の階層型NNのことを指す。
3層でも中間層のノードが十分なら任意の関数を近似できるという理論的な利点があったが、局所最適解や勾配消去問題等の技術的な問題があった。
中間層の数を増やすことで効果的に学習ができることが判明し、活性化関数の工夫がされたことにより、2010年代に普及した。
##再帰ニューラルネット

##畳み込みニューラルネット
畳み込み構造を含んだNN、画像処理特に使われる。
##再帰結合ニューラルネット
系列データ処理のために作られたNN、前回時刻の入力の情報を現在の入力に使うための再帰結合入力がある。
音声認識、自然言語処理で使われる。


##画像処理分野

##音声処理分野

##各種ツール
*Cafee*
*Chainer*
*Google Tensorflow*
*Chainer gogh*
*Pylearn2*

*Imagenet*









